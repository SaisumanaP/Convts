{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speech-separation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNoPiFtuUoC7yf3/NaBnzAv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4nzfoun37JMa"},"source":["# Speech Separation by Pretrained Models"]},{"cell_type":"code","metadata":{"id":"BQ7c_pW-3Gtj"},"source":["%%bash\n","git clone https://github.com/tky823/DNN-based_source_separation.git\n","\n","cd \"./DNN-based_source_separation/egs/tutorials/\"\n","\n","# To install torch & torchaudio\n","pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPAGmvZV2_yV"},"source":["%%bash\n","# Download speech dataset\n","for spk in aew axb bdl ; do\n","    wget \"http://festvox.org/cmu_arctic/packed/cmu_us_${spk}_arctic.tar.bz2\"\n","    tar -xjvf \"./cmu_us_${spk}_arctic.tar.bz2\" \n","done"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVrpBGYQ3Jsv"},"source":["import sys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6NcBVuehQMK"},"source":["sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cncPvFUB3Nd2"},"source":["import IPython.display as ipd\n","import torch\n","import torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCndL0s5csct"},"source":["torch.manual_seed(111)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"grI0SYYB3PzV"},"source":["from models.deep_clustering import DeepClustering\n","from models.danet import DANet, FixedAttractorDANet\n","from models.adanet import ADANet\n","from models.lstm_tasnet import LSTMTasNet\n","from models.conv_tasnet import ConvTasNet\n","from models.dprnn_tasnet import DPRNNTasNet\n","from models.dptnet import DPTNet\n","from models.sepformer import SepFormer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNSGY59z3Tok"},"source":["waveform_aew, sample_rate = torchaudio.load(\"/content/cmu_us_aew_arctic/wav/arctic_a0001.wav\")\n","waveform_axb, sample_rate = torchaudio.load(\"/content/cmu_us_axb_arctic/wav/arctic_a0002.wav\")\n","waveform_bdl, sample_rate = torchaudio.load(\"/content/cmu_us_bdl_arctic/wav/arctic_a0003.wav\")\n","SAMPLE_RATE_WSJ0 = 8000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxUsAPHu5Kl2"},"source":["resampler = torchaudio.transforms.Resample(sample_rate, SAMPLE_RATE_WSJ0)\n","waveform_aew = resampler(waveform_aew)\n","waveform_axb = resampler(waveform_axb)\n","waveform_bdl = resampler(waveform_bdl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SS_eYo6b4A6e"},"source":["T_min = min(waveform_aew.size(-1), waveform_axb.size(-1), waveform_bdl.size(-1))\n","waveform_aew, waveform_axb, waveform_bdl = waveform_aew[:, :T_min], waveform_axb[:, :T_min], waveform_bdl[:, :T_min]\n","display(ipd.Audio(waveform_aew, rate=SAMPLE_RATE_WSJ0))\n","display(ipd.Audio(waveform_axb, rate=SAMPLE_RATE_WSJ0))\n","display(ipd.Audio(waveform_bdl, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28_wMyLv75ti"},"source":["## 2 speakers"]},{"cell_type":"code","metadata":{"id":"zizEZrvp5ACM"},"source":["n_sources = 2\n","mixture = waveform_aew + waveform_axb\n","display(ipd.Audio(mixture, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = DeepClustering.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = DeepClustering.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=model.threshold, n_sources=n_sources, iter_clustering=None)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"metadata":{"id":"HtrcNjmvOyzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlGlHJfxhKxr"},"source":["model = DANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = DANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=model.threshold, n_sources=n_sources, iter_clustering=None)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGPk_u-xPmlg"},"source":["model = FixedAttractorDANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = FixedAttractorDANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUvlBAe6snIG"},"source":["model = ADANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = ADANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=40, n_sources=n_sources)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvRRn3-r4Eyb"},"source":["model = LSTMTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqSe2Evd6MRf"},"source":["model = ConvTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDrHvPXy6pnJ"},"source":["model = DPRNNTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u82Qi5ML6wwr"},"source":["model = DPTNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aq6fE6ZThlzP"},"source":["model = SepFormer.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3ixQJPb8F2I"},"source":["## 3 speakers"]},{"cell_type":"code","metadata":{"id":"Ri9q1DEZ699U"},"source":["n_sources = 3\n","mixture = waveform_aew + waveform_axb + waveform_bdl\n","display(ipd.Audio(mixture, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = DeepClustering.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = DeepClustering.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=model.threshold, n_sources=n_sources, iter_clustering=None)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"metadata":{"id":"D8wAeJ70Jlnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JA_XX5gLbhav"},"source":["model = DANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = DANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=model.threshold, n_sources=n_sources, iter_clustering=None)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqsfCffuhdm1"},"source":["model = FixedAttractorDANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = FixedAttractorDANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4kbZGC82iVZ"},"source":["model = ADANet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","wrapper_model = ADANet.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = wrapper_model(input, threshold=40, n_sources=n_sources)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LSTMTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"metadata":{"id":"7Gkqdb3xEMpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTWK_e4P8KKa"},"source":["model = ConvTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8GXERi08SEA"},"source":["model = DPRNNTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = DPTNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"metadata":{"id":"pZ1i8-rxEJ2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDy6cBP38iRm"},"source":["model = SepFormer.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0)\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LdEncSTFbyZd"},"execution_count":null,"outputs":[]}]}