{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"skip-gram_naive.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMUKlgSUptPTf/rM73W0XEo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Word2Vec using skip-gram"],"metadata":{"id":"TLy1WPywSxLU"}},{"cell_type":"markdown","source":["Reference:\n","- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)"],"metadata":{"id":"NwULeluwLm8s"}},{"cell_type":"code","source":["%%bash\n","git clone https://github.com/tky823/DNN-based_source_separation.git"],"metadata":{"id":"Xjluj92OCIj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AagZIJljmldY"},"outputs":[],"source":["import os\n","import sys\n","from functools import partial"]},{"cell_type":"code","source":["sys.path.append(\"/content/DNN-based_source_separation/egs/tutorials/word2vec/src\")"],"metadata":{"id":"Ia7lDBf-DDBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"kd4Vi8-MP3ON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams[\"figure.dpi\"] = 100"],"metadata":{"id":"_PPU3cbLP5mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"N5Goa5-JnKcN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchtext\n","from torchtext.data import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer"],"metadata":{"id":"Na-it9zHnLcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from adhoc_utils import build_vocab\n","from adhoc_driver import Trainer"],"metadata":{"id":"jvEPjxROFZHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch, text_pipeline, context_size=4, max_seq_length=256):\n","    batch_input, batch_target = [], []\n","    for text in batch:\n","        text_tokens_ids = text_pipeline(text)\n","        raw_seq_length = len(text_tokens_ids)\n","\n","        if raw_seq_length < 2 * context_size + 1:\n","            continue\n","\n","        if max_seq_length is not None:\n","            _max_seq_length = min(max_seq_length, raw_seq_length)\n","            high = max(0, raw_seq_length - _max_seq_length)\n","            start_idx = torch.randint(0, high+1, ())\n","            end_idx = start_idx + _max_seq_length\n","            text_tokens_ids = text_tokens_ids[start_idx: end_idx]\n","            seq_length = len(text_tokens_ids)\n","        else:\n","            seq_length = raw_seq_length\n","\n","        for start_idx in range(seq_length - 2 * context_size):\n","            end_idx = start_idx + 2 * context_size + 1\n","            token_id_sequence = text_tokens_ids[start_idx: end_idx]\n","            input = token_id_sequence.pop(context_size)\n","            target = token_id_sequence\n","            batch_input.append(input)\n","            batch_target.append(target)\n","\n","    batch_input = torch.tensor(batch_input, dtype=torch.long) # (num_samples,)\n","    batch_target = torch.tensor(batch_target, dtype=torch.long) # (num_samples, 2 * context_size)\n","\n","    return batch_input, batch_target"],"metadata":{"id":"AemZRqa-n1HX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SkipGram(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, bias=False, max_norm=1):\n","        super().__init__()\n","\n","        self.vocab_size, self.embed_dim = vocab_size, embed_dim\n","        self.max_norm = max_norm\n","\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, max_norm=max_norm)\n","        self.linear = nn.Linear(embed_dim, vocab_size, bias=bias)\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Args:\n","            input: (batch_size,) or (batch_size, context_size)\n","        Returns:\n","            output: (batch_size, vocab_size) or (batch_size, vocab_size, context_size)\n","        \"\"\"\n","        x = self.embedding(input)\n","        x = self.linear(x)\n","\n","        if x.dim() == 3:\n","            output = x.permute(0, 2, 1)\n","        else:\n","            output = x\n","\n","        return output\n","\n","    def get_embedding_weights(self):\n","        \"\"\"\n","        Returns:\n","            weights: (vocab_size, embed_dim)\n","        \"\"\"\n","        max_norm = self.max_norm\n","\n","        weights = self.embedding.weight.data\n","        norm = torch.linalg.vector_norm(weights, dim=1, keepdim=True) # (vocab_size, 1)\n","        weights = torch.where(norm > max_norm, max_norm * weights / norm, weights)\n","\n","        return weights"],"metadata":{"id":"a6duDtQBn3MV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AdhocTrainer(Trainer):\n","    def __init__(self, model, loader, criterion, optimizer, config):\n","        super().__init__(model, loader, criterion, optimizer, config)\n","\n","    def run_one_epoch_train(self, epoch):\n","        context_size = self.context_size\n","        train_loss = 0\n","\n","        self.model.train()\n","\n","        for idx, (input, target) in enumerate(self.train_loader):\n","            if self.use_cuda:\n","                input = input.cuda()\n","                target = target.cuda()\n","\n","            output = self.model(input) # (num_samples, vocab_size)\n","            output = output.unsqueeze(dim=-1) # (num_samples, vocab_size, 1)\n","            output = output.expand(-1, -1, 2 * context_size) # (num_samples, vocab_size, 2 * context_size)\n","            loss = self.criterion(output, target) # (num_samples, 2 * context_size)\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            if (idx + 1) % 100 == 0:\n","                print(\"[Epoch {}/{}] iter {}/{} loss: {:.5f}\".format(epoch + 1, self.epochs, idx + 1, len(self.train_loader), loss.item()), flush=True)\n","\n","        train_loss /= len(self.train_loader)\n","\n","        return train_loss\n","\n","    def run_one_epoch_eval(self, epoch):\n","        context_size = self.context_size\n","        valid_loss = 0\n","\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            for idx, (input, target) in enumerate(self.valid_loader):\n","                if self.use_cuda:\n","                    input = input.cuda()\n","                    target = target.cuda()\n","\n","                output = self.model(input) # (num_samples, vocab_size)\n","                output = output.unsqueeze(dim=-1) # (num_samples, vocab_size, 1)\n","                output = output.expand(-1, -1, 2 * context_size) # (num_samples, vocab_size, 2 * context_size)\n","                loss = self.criterion(output, target) # (num_samples, 2 * context_size)\n","                valid_loss += loss.item()\n","\n","        valid_loss /= len(self.valid_loader)\n","\n","        return valid_loss"],"metadata":{"id":"lq9BBGUZn4bS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = \"WikiText2\" # or \"WikiText103\"\n","exp_dir = \"./exp\"\n","\n","config = {\n","    \"system\": {\n","        \"seed\": 111,\n","        \"use_cuda\":  torch.cuda.is_available(),\n","        \"eps\": 1e-12\n","    },\n","    \"dataset\": dataset,\n","    \"vocab\": {\n","        \"min_freq\": 50\n","    },\n","    \"vocab_path\": os.path.join(exp_dir, dataset, \"vocab/vocab.pth\"),\n","    \"context_size\": 4,\n","    \"model\": {\n","        \"embed_dim\": 300\n","    },\n","    \"optim\": {\n","        \"lr\": 1e-3\n","    },\n","    \"batch_size\": 96,\n","    \"epochs\": 100,\n","    \"model_dir\": os.path.join(exp_dir, dataset, \"skip-gram_naive/model\"),\n","    \"loss_dir\": os.path.join(exp_dir, dataset, \"skip-gram_naive/loss\"),\n","    \"continue_from\": None # None or os.path.join(exp_dir, dataset, \"skip-gram_naive/model/last.pth\")\n","}"],"metadata":{"id":"mu8fimrF05d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(config[\"system\"][\"seed\"])"],"metadata":{"id":"OxDZ6LHun51v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config[\"dataset\"] == \"WikiText2\":\n","    train_iter = torchtext.datasets.WikiText2(root=\"./\", split='train')\n","    valid_iter = torchtext.datasets.WikiText2(root=\"./\", split='valid')\n","elif config[\"dataset\"] == \"WikiText103\":\n","    train_iter = torchtext.datasets.WikiText103(root=\"./\", split='train')\n","    valid_iter = torchtext.datasets.WikiText103(root=\"./\", split='valid')\n","else:\n","    raise NotImplementedError(\"Not support {}.\".format(config[\"dataset\"]))\n","\n","train_iter = to_map_style_dataset(train_iter)\n","valid_iter = to_map_style_dataset(valid_iter)"],"metadata":{"id":"iosov0mOVbuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n","\n","if os.path.exists(config[\"vocab_path\"]):\n","    vocab = torch.load(config[\"vocab_path\"])\n","else:\n","    vocab = build_vocab(train_iter, tokenizer, min_freq=config[\"vocab\"][\"min_freq\"])\n","    vocab_dir = os.path.dirname(config[\"vocab_path\"])\n","    os.makedirs(vocab_dir, exist_ok=True)\n","    torch.save(vocab, config[\"vocab_path\"])\n","\n","text_pipeline = lambda x: vocab(tokenizer(x))"],"metadata":{"id":"EnjJL3LMVkQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader = {}\n","loader[\"train\"] = torch.utils.data.DataLoader(train_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn, text_pipeline=text_pipeline, context_size=config[\"context_size\"]))\n","loader[\"valid\"] = torch.utils.data.DataLoader(valid_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn, text_pipeline=text_pipeline, context_size=config[\"context_size\"]))"],"metadata":{"id":"7ti3agshn7CD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SkipGram(vocab_size=len(vocab), embed_dim=config[\"model\"][\"embed_dim\"])\n","print(model)"],"metadata":{"id":"C1YC1aP0n9k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config[\"system\"][\"use_cuda\"]:\n","    model.cuda()\n","    print(\"Uses CUDA.\")\n","else:\n","    print(\"Does NOT use CUDA.\")"],"metadata":{"id":"DD3MhQc_MQ_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=config[\"optim\"][\"lr\"])"],"metadata":{"id":"asjhWBw8n_oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"Y3_GkzgtoBFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"bfdDiUDO9b8B"}},{"cell_type":"code","source":["trainer = AdhocTrainer(model, loader, criterion, optimizer, config)\n","trainer.run()"],"metadata":{"id":"XuS7gOkVoCMf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Examine"],"metadata":{"id":"0Td3NaOu9dnl"}},{"cell_type":"code","source":["from word2vec import Word2Vec"],"metadata":{"id":"E8NXewgrKAgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = os.path.join(config[\"model_dir\"], \"last.pth\")\n","package = torch.load(model_path, map_location=lambda storage, loc: storage)\n","\n","model = SkipGram(vocab_size=len(vocab), embed_dim=config[\"model\"][\"embed_dim\"])\n","model.load_state_dict(package[\"state_dict\"])"],"metadata":{"id":"OtpN4zrbEH6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2vec = Word2Vec(model.get_embedding_weights(), vocab, eps=config[\"system\"][\"eps\"])"],"metadata":{"id":"ExWt_FgqG2hm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similar_words = word2vec.get_similar_words(\"mother\")\n","print(similar_words)"],"metadata":{"id":"2keMwNkJG3KW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["son_vec, man_vec, woman_vec = word2vec([\"son\", \"man\", \"woman\"])\n","similar_words = word2vec.get_similar_words_from_vec(son_vec - man_vec + woman_vec)\n","print(similar_words)"],"metadata":{"id":"AJlj9wKgB5Bz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"IjyjleCPdCED"},"execution_count":null,"outputs":[]}]}