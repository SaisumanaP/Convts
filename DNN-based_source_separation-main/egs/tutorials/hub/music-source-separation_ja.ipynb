{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"music-source-separation_ja.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7OGCey3UN9fqMKF1tFFDy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pvi053-wDnPw"},"source":["# 事前学習済みモデルによる楽音分離\n","自前の音楽ファイルで分離を試したい場合は，以下を参照してください．\n","- `egs/tutorials/conv-tasnet/separate_music_ja.ipynb` (Conv-TasNet)\n","- `egs/tutorials/mm-dense-lstm/separate_music_ja.ipynb` (MMDenseLSTM)\n","- `egs/tutorials/umx/separate_music_ja.ipynb` (Open-Unmix)\n","- `egs/tutorials/xumx/separate_music_ja.ipynb` (CrossNet-Open-Unmix)\n","- `egs/tutorials/d3net/separate_music_ja.ipynb` (D3Net)"]},{"cell_type":"code","metadata":{"id":"PiaO5Q9SDglU"},"source":["%%bash\n","git clone https://github.com/tky823/DNN-based_source_separation.git\n","\n","cd \"./DNN-based_source_separation/egs/tutorials/\"\n","\n","# To install torch & torchaudio\n","pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6OBf_XKDppE"},"source":["%%bash\n","# Download music datset\n","wget \"https://zenodo.org/api/files/1ff52183-071a-4a59-923f-7a31c4762d43/MUSDB18-7-STEMS.zip\"\n","unzip \"./MUSDB18-7-STEMS.zip\"\n","\n","# Convert .mp4 to .wav\n","cd \"./train\"\n","\n","for stem in *.stem.mp4 ; do\n","    name=`echo $stem | awk -F\".stem.mp4\" '{$0=$1}1'`;\n","    echo \"$stem\"\n","    mkdir \"$name\"\n","    cd \"$name\"\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:0 -vn mixture.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:1 -vn drums.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:2 -vn bass.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:3 -vn other.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:4 -vn vocals.wav\n","    cd \"../\"\n","done"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEDz29vCDruc"},"source":["import sys\n","sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyMzvlTbDs_e"},"source":["import IPython.display as ipd\n","import torch\n","import torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AflTmQYDt-3"},"source":["from models.conv_tasnet import ConvTasNet\n","from models.mm_dense_lstm import MMDenseLSTM, ParallelMMDenseLSTM\n","from models.umx import OpenUnmix, ParallelOpenUnmix\n","from models.xumx import CrossNetOpenUnmix\n","from models.d3net import D3Net, ParallelD3Net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPckRpcaDvEo"},"source":["name = \"ANiMAL - Rockshow\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTkaeERhDwQ3"},"source":["waveform_bass, sample_rate = torchaudio.load(\"/content/train/{}/bass.wav\".format(name))\n","waveform_drums, sample_rate = torchaudio.load(\"/content/train/{}/drums.wav\".format(name))\n","waveform_other, sample_rate = torchaudio.load(\"/content/train/{}/other.wav\".format(name))\n","waveform_vocals, sample_rate = torchaudio.load(\"/content/train/{}/vocals.wav\".format(name))\n","\n","print(\"bass\")\n","display(ipd.Audio(waveform_bass, rate=sample_rate))\n","print(\"drums\")\n","display(ipd.Audio(waveform_drums, rate=sample_rate))\n","print(\"other\")\n","display(ipd.Audio(waveform_other, rate=sample_rate))\n","print(\"vocals\")\n","display(ipd.Audio(waveform_vocals, rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EYXK_U8Dxa4"},"source":["mixture = waveform_bass + waveform_drums + waveform_other + waveform_vocals\n","display(ipd.Audio(mixture, rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvhUF1cJDynJ"},"source":["model = ConvTasNet.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    mean = input.mean(dim=3, keepdim=True)\n","    std = input.std(dim=3, keepdim=True)\n","    input = (input - mean) / std\n","    output = model(input)\n","    output = std * output + mean\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8SqGuPSDzz0"},"source":["model = ParallelMMDenseLSTM.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelMMDenseLSTM.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"piz7393JD04M"},"source":["model = ParallelOpenUnmix.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelOpenUnmix.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4D2IxD9D5P0"},"source":["model = CrossNetOpenUnmix.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = CrossNetOpenUnmix.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dj0IR0lAD6ri"},"source":["model = ParallelD3Net.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelD3Net.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpvK-Q8RD7-w"},"source":[""],"execution_count":null,"outputs":[]}]}