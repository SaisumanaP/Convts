{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speech-commands.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPiV85aLORxauiCic0TmoOV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g-NljVOwkhZ2"},"source":["# Siamese Network\n","Metric learning by speech commands dataset (30min.)"]},{"cell_type":"code","metadata":{"id":"xIMz88UakZ6I"},"source":["%%shell\n","pip install torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAS1B0xokqKP"},"source":["%%shell\n","git clone https://github.com/tky823/DNN-based_source_separation.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MgWzIw_kqH1"},"source":["%cd \"/content/DNN-based_source_separation/egs/tutorials/siamese-net\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vQDgQsIkqFZ"},"source":["import sys\n","sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGTb7bc4kqC1"},"source":["import os\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1nSShZRkp__"},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqDhNFZgkp9l"},"source":["plt.rcParams['font.size'] = 18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyURaqMDkp7y"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision, torchaudio\n","from torchaudio.datasets import SPEECHCOMMANDS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mI4tD0Kkp3l"},"source":["from criterion.distance import L2Loss\n","from criterion.metric_learn import ContrastiveWithDistanceLoss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0aBCPoBk-ph"},"source":["## Generate dataset\n","we use only 5 classes."]},{"cell_type":"code","metadata":{"id":"BPjIG4Gikp0y"},"source":["classes = [\n","    \"zero\", \"one\", \"two\", \"three\", \"four\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahISf_BfkpyC"},"source":["class SpeechCommandsDataset(SPEECHCOMMANDS):\n","    def __init__(self, subset=None, transform=None, classes=classes):\n","        super().__init__(\"./\", download=True)\n","\n","        self.transform = transform\n","        self.classes = classes\n","\n","        def load_all_paths(filename):\n","            filepath = os.path.join(self._path, filename)\n","            with open(filepath) as fileobj:\n","                paths = [os.path.join(self._path, line.strip()) for line in fileobj]\n","            return paths\n","        \n","        def extract_number(paths):\n","            target_paths = []\n","            targets = []\n","            for path in paths:\n","                label = path.split(\"/\")[-2]\n","                if label in self.classes:\n","                    target_paths.append(path)\n","                    targets.append(self.classes.index(label))\n","            \n","            return target_paths, torch.tensor(targets)\n","\n","        if subset == \"validation\":\n","            paths = load_all_paths(\"validation_list.txt\")\n","            self._walker, self.targets = extract_number(paths)\n","        elif subset == \"testing\":\n","            paths = load_all_paths(\"testing_list.txt\")\n","            self._walker, self.targets = extract_number(paths)\n","        elif subset == \"training\":\n","            excludes = load_all_paths(\"validation_list.txt\") + load_all_paths(\"testing_list.txt\")\n","            excludes = set(excludes)\n","            paths = [w for w in self._walker if w not in excludes]\n","            self._walker, self.targets = extract_number(paths)\n","    \n","    def __getitem__(self, idx):\n","        input, sr, label, speaker_id, utterance_id = super().__getitem__(idx)\n","        target = self.classes.index(label)\n","        \n","        padding = sr - input.size(-1)\n","        padding_left = padding // 2\n","        padding_right = padding - padding_left\n","        input = F.pad(input, (padding_left, padding_right))\n","\n","        if self.transform is not None:\n","            input = self.transform(input)\n","\n","        return input, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BdyTN-vCkpvP"},"source":["class PairedSpeechCommandsDataset:\n","    def __init__(self, subset=\"training\", transform=None, num_samples=None):\n","        self.original_dataset = SpeechCommandsDataset(subset=subset, transform=transform)\n","        self.n_class = len(self.original_dataset.classes)\n","\n","        self.class_list = list(range(self.n_class))\n","        self.target_list = []\n","        for class_idx in self.class_list:\n","            self.target_list.append(torch.where(self.original_dataset.targets==class_idx)[0].tolist())\n","\n","        if num_samples is None:\n","            self.num_samples = len(self.original_dataset)\n","        else:\n","            self.num_samples = num_samples\n","    \n","    def __getitem__(self, idx):\n","        random.shuffle(self.class_list)\n","        positive_class = self.class_list[0]\n","        negative_class = self.class_list[1]\n","        is_same = random.randint(0, 1)\n","\n","        if is_same == 1:\n","            idx_left, idx_right = random.sample(self.target_list[positive_class], 2)\n","        else:\n","            idx_left = random.choice(self.target_list[positive_class])\n","            idx_right = random.choice(self.target_list[negative_class])\n","\n","        (input_left, _), (input_right, _) = self.original_dataset[idx_left], self.original_dataset[idx_right]\n","\n","        return input_left, input_right, is_same\n","    \n","    def __len__(self):\n","        return self.num_samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8Iq3dYVkpse"},"source":["random.seed(111)\n","torch.manual_seed(111)\n","num_samples = 500000\n","batch_size = 64\n","sr = 16000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMobleJhkpp0"},"source":["class Log10:\n","    def __init__(self, eps=1e-12):\n","        self.eps = eps\n","    \n","    def __call__(self, input):\n","        return 10 * torch.log10(input + self.eps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPifbKSJkpnD"},"source":["transform = torchvision.transforms.Compose([\n","    torchaudio.transforms.Spectrogram(),\n","    Log10()\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvdpR5j6kpkS"},"source":["train_dataset = PairedSpeechCommandsDataset(\"training\", transform=transform, num_samples=num_samples)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxPqjH_flYaj"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"0u36gYYykphk"},"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dropout=0.3):\n","        super().__init__()\n","        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride)\n","        self.prelu = nn.PReLU()\n","        self.pool2d = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, input):\n","        x = self.conv2d(input)\n","        x = self.prelu(x)\n","        x = self.pool2d(x)\n","        output = self.dropout(x)\n","\n","        return output\n","\n","class BasicModel(nn.Module):\n","    def __init__(self, embed_dim=2, dropout=0.3):\n","        super().__init__()\n","\n","        net = []\n","        net.append(ConvBlock(1, 16, 5))\n","        net.append(ConvBlock(16, 32, 3))\n","        net.append(ConvBlock(32, 64, 3))\n","        net.append(ConvBlock(64, 128, 3))\n","\n","        fc_net = []\n","        fc_net.append(nn.Linear(128*10*3, 512))\n","        fc_net.append(nn.PReLU())\n","        fc_net.append(nn.Linear(512, embed_dim))\n","\n","        self.net = nn.Sequential(*net)\n","        self.fc_net = nn.Sequential(*fc_net)\n","        \n","    def forward(self, input):\n","        x = self.net(input)\n","        x = x.view(-1, 128*10*3)\n","        output = self.fc_net(x)\n","        \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnMhArkylcgB"},"source":["model = BasicModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_12LoRslcdG"},"source":["print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oehm_1yilcaz"},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSw5KI39ln1B"},"source":["## Training\n","Enbed in 2D"]},{"cell_type":"code","metadata":{"id":"5ULdhhmDlfxw"},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = L2Loss()\n","contrastive_criterion = ContrastiveWithDistanceLoss(distance_fn=criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTdpUmrLlfvN"},"source":["model.train()\n","\n","train_loss = []\n","for idx, (input_left, input_right, is_same) in enumerate(train_loader):\n","    if torch.cuda.is_available():\n","        input_left, input_right, is_same = input_left.cuda(), input_right.cuda(), is_same.cuda()\n","\n","    optimizer.zero_grad()\n","\n","    output_left = model(input_left)\n","    output_right = model(input_right)\n","\n","    loss = contrastive_criterion(output_left, output_right, is_same)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (idx + 1) % 50 == 0:\n","        print(\"{}/{} Loss: {:.5f}\".format(idx + 1, len(train_loader), loss.item()))\n","    \n","    train_loss.append(loss.item())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJt4w1Bglfsf"},"source":["train_loss = np.array(train_loss)\n","average_loss = 0\n","\n","for i in range(100):\n","    average_loss = average_loss + train_loss[i: -100 + i]\n","\n","average_loss = average_loss / 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHzUNkOelfp7"},"source":["plt.figure(figsize=(12, 8))\n","plt.plot(train_loss[100:], color='deepskyblue')\n","plt.plot(average_loss, color='black')\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","# plt.savefig(\"./loss/train_loss.png\", bbox_inches='tight')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZS0Ja5Pj5e_"},"source":["# For visualization\n","train_dataset = SpeechCommandsDataset(\"training\", transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BG496aVgj6KO"},"source":["model.eval()\n","\n","x = []\n","labels = []\n","\n","with torch.no_grad():\n","    for input, target in train_loader:\n","        if torch.cuda.is_available():\n","            input, target = input.cuda(), target.cuda()\n","        output = model(input)\n","        x.append(output.squeeze(dim=0).cpu().numpy())\n","        label = target.squeeze(dim=0).cpu().item()\n","        labels.append(label)\n","\n","x = np.array(x)\n","labels = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6ZuzEVBj7vw"},"source":["plt.figure(figsize=(12, 8))\n","\n","for class_idx, label in enumerate(test_dataset.classes):\n","    x_class = x[labels == class_idx]\n","    plt.scatter(x_class[:, 0], x_class[:, 1], label=label)\n","\n","plt.legend()\n","plt.show()\n","# plt.savefig(\"./embedding/train_embedding.png\", bbox_inches='tight')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bnUox1Qnly4G"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"-6Mz_pM1jtN7"},"source":["test_dataset = SpeechCommandsDataset(\"testing\", transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJcu76bdlxg9"},"source":["model.eval()\n","\n","x = []\n","labels = []\n","\n","with torch.no_grad():\n","    for input, target in test_loader:\n","        if torch.cuda.is_available():\n","            input, target = input.cuda(), target.cuda()\n","        output = model(input)\n","        x.append(output.squeeze(dim=0).cpu().numpy())\n","        label = target.squeeze(dim=0).cpu().item()\n","        labels.append(label)\n","\n","x = np.array(x)\n","labels = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQWiqSw3lxeL"},"source":["plt.figure(figsize=(12, 8))\n","\n","for class_idx, label in enumerate(test_dataset.classes):\n","    x_class = x[labels == class_idx]\n","    plt.scatter(x_class[:, 0], x_class[:, 1], label=label)\n","\n","plt.legend()\n","plt.show()\n","# plt.savefig(\"./embedding/train_embedding.png\", bbox_inches='tight')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rc_WSRW-lcXs"},"source":[""],"execution_count":null,"outputs":[]}]}