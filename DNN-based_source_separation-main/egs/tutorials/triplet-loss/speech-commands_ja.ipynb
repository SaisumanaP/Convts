{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speech-commands_ja.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNeegbEaA9X7Cc4uuC1ekr6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RGBrPLGzurl7"},"source":["# Triplet Loss\n","Speech commandsデータセットで距離学習\n","（50分）"]},{"cell_type":"code","metadata":{"id":"cf6hNm1zuGNB"},"source":["%%shell\n","pip install torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oynaFE6nuO4H"},"source":["%%shell\n","git clone https://github.com/tky823/DNN-based_source_separation.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHWaLfuquO1r"},"source":["%cd \"/content/DNN-based_source_separation/egs/tutorials/triplet-loss\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycxPwQd-uOy6"},"source":["import sys\n","sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzj2BnyxuOwW"},"source":["import os\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEyg8YxhuOtf"},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTY7E0YmuOqy"},"source":["plt.rcParams['font.size'] = 18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmaPr0l0uOoL"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision, torchaudio\n","from torchaudio.datasets import SPEECHCOMMANDS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDp1KbkFuOll"},"source":["from criterion.metric_learn import TripletLoss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ZpFF2EIv0gg"},"source":["## データセットの作成\n","5クラスのみ用いる．"]},{"cell_type":"code","metadata":{"id":"srwjW3y-uOi-"},"source":["classes = [\n","    \"zero\", \"one\", \"two\", \"three\", \"four\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1nYQW6EuOgf"},"source":["class SpeechCommandsDataset(SPEECHCOMMANDS):\n","    def __init__(self, subset=None, transform=None, classes=classes):\n","        super().__init__(\"./\", download=True)\n","\n","        self.transform = transform\n","        self.classes = classes\n","\n","        def load_all_paths(filename):\n","            filepath = os.path.join(self._path, filename)\n","            with open(filepath) as fileobj:\n","                paths = [os.path.join(self._path, line.strip()) for line in fileobj]\n","            return paths\n","        \n","        def extract_number(paths):\n","            target_paths = []\n","            targets = []\n","            for path in paths:\n","                label = path.split(\"/\")[-2]\n","                if label in self.classes:\n","                    target_paths.append(path)\n","                    targets.append(self.classes.index(label))\n","            \n","            return target_paths, torch.tensor(targets)\n","\n","        if subset == \"validation\":\n","            paths = load_all_paths(\"validation_list.txt\")\n","            self._walker, self.targets = extract_number(paths)\n","        elif subset == \"testing\":\n","            paths = load_all_paths(\"testing_list.txt\")\n","            self._walker, self.targets = extract_number(paths)\n","        elif subset == \"training\":\n","            excludes = load_all_paths(\"validation_list.txt\") + load_all_paths(\"testing_list.txt\")\n","            excludes = set(excludes)\n","            paths = [w for w in self._walker if w not in excludes]\n","            self._walker, self.targets = extract_number(paths)\n","    \n","    def __getitem__(self, idx):\n","        input, sr, label, speaker_id, utterance_id = super().__getitem__(idx)\n","        target = self.classes.index(label)\n","        \n","        padding = sr - input.size(-1)\n","        padding_left = padding // 2\n","        padding_right = padding - padding_left\n","        input = F.pad(input, (padding_left, padding_right))\n","\n","        if self.transform is not None:\n","            input = self.transform(input)\n","\n","        return input, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1R27EB_uOd3"},"source":["class TripletSpeechCommandsDataset:\n","    def __init__(self, subset=\"training\", transform=None, num_samples=None):\n","        self.original_dataset = SpeechCommandsDataset(subset=subset, transform=transform)\n","        self.n_class = len(self.original_dataset.classes)\n","\n","        self.class_list = list(range(self.n_class))\n","        self.target_list = []\n","        for class_idx in self.class_list:\n","            self.target_list.append(torch.where(self.original_dataset.targets==class_idx)[0].tolist())\n","\n","        if num_samples is None:\n","            self.num_samples = len(self.original_dataset)\n","        else:\n","            self.num_samples = num_samples\n","    \n","    def __getitem__(self, idx):\n","        random.shuffle(self.class_list)\n","        positive_class = self.class_list[0]\n","        negative_class = self.class_list[1]\n","\n","        anchor_idx, positive_idx = random.sample(self.target_list[positive_class], 2)\n","        negative_idx = random.choice(self.target_list[negative_class])\n","\n","        (anchor, _), (positive, _), (negative, _) = self.original_dataset[anchor_idx], self.original_dataset[positive_idx], self.original_dataset[negative_idx]\n","\n","        return anchor, positive, negative\n","    \n","    def __len__(self):\n","        return self.num_samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PjAeN0Iuvz2"},"source":["random.seed(111)\n","torch.manual_seed(111)\n","num_samples = 500000\n","batch_size = 64\n","sr = 16000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xe3Ch7tDuvxb"},"source":["class Log10:\n","    def __init__(self, eps=1e-12):\n","        self.eps = eps\n","    \n","    def __call__(self, input):\n","        return 10 * torch.log10(input + self.eps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7DesnxfuvvJ"},"source":["transform = torchvision.transforms.Compose([\n","    torchaudio.transforms.Spectrogram(),\n","    Log10()\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"845EpOu_u1Zz"},"source":["train_dataset = TripletSpeechCommandsDataset(\"training\", transform=transform, num_samples=num_samples)\n","test_dataset = SpeechCommandsDataset(\"testing\", transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQOUPh1YwCo5"},"source":["## モデル"]},{"cell_type":"code","metadata":{"id":"v8H8UNSxu21B"},"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dropout=0.3):\n","        super().__init__()\n","        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride)\n","        self.prelu = nn.PReLU()\n","        self.pool2d = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, input):\n","        x = self.conv2d(input)\n","        x = self.prelu(x)\n","        x = self.pool2d(x)\n","        output = self.dropout(x)\n","\n","        return output\n","\n","class BasicModel(nn.Module):\n","    def __init__(self, embed_dim=2, dropout=0.3):\n","        super().__init__()\n","\n","        net = []\n","        net.append(ConvBlock(1, 16, 5))\n","        net.append(ConvBlock(16, 32, 3))\n","        net.append(ConvBlock(32, 64, 3))\n","        net.append(ConvBlock(64, 128, 3))\n","\n","        fc_net = []\n","        fc_net.append(nn.Linear(128*10*3, 512))\n","        fc_net.append(nn.PReLU())\n","        fc_net.append(nn.Linear(512, embed_dim))\n","\n","        self.net = nn.Sequential(*net)\n","        self.fc_net = nn.Sequential(*fc_net)\n","        \n","    def forward(self, input):\n","        x = self.net(input)\n","        x = x.view(-1, 128*10*3)\n","        output = self.fc_net(x)\n","        \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh79Oh_1u4PT"},"source":["model = BasicModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq1e4UGEu5l9"},"source":["print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D76p9wgl0_Z_"},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Gq-sRYl5Geu"},"source":["## 学習\n","2次元に埋め込む"]},{"cell_type":"code","metadata":{"id":"38Oilyqtu7LJ"},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = TripletLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX2TjSg5u7p3"},"source":["model.train()\n","\n","train_loss = []\n","for idx, (input_anchor, input_positive, input_negative) in enumerate(train_loader):\n","    if torch.cuda.is_available():\n","        input_anchor, input_positive, input_negative = input_anchor.cuda(), input_positive.cuda(), input_negative.cuda()\n","\n","    optimizer.zero_grad()\n","\n","    output_anchor = model(input_anchor)\n","    output_positive = model(input_positive)\n","    output_negative = model(input_negative)\n","    \n","    loss = criterion(output_anchor, output_positive, output_negative)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (idx + 1) % 50 == 0:\n","        print(\"{}/{} Loss: {:.5f}\".format(idx + 1, len(train_loader), loss.item()))\n","    \n","    train_loss.append(loss.item())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ch9auIn6ugtO"},"source":["train_loss = np.array(train_loss)\n","average_loss = 0\n","\n","for i in range(100):\n","    average_loss = average_loss + train_loss[i: -100 + i]\n","\n","average_loss = average_loss / 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkatWMixugrK"},"source":["plt.figure(figsize=(12, 8))\n","plt.plot(train_loss[100:], color='deepskyblue')\n","plt.plot(average_loss, color='black')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JzDli70h5gRj"},"source":["## テスト"]},{"cell_type":"code","metadata":{"id":"XZXDi7x9ugoz"},"source":["model.eval()\n","\n","x = []\n","labels = []\n","\n","with torch.no_grad():\n","    for input, target in test_loader:\n","        input, target = input.cuda(), target.cuda()\n","        output = model(input)\n","        x.append(output.squeeze(dim=0).cpu().numpy())\n","        label = target.squeeze(dim=0).cpu().item()\n","        labels.append(label)\n","\n","x = np.array(x)\n","labels = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geJXsN1uugma"},"source":["plt.figure(figsize=(12, 8))\n","\n","for class_idx, label in enumerate(test_dataset.classes):\n","    x_class = x[labels == class_idx]\n","    plt.scatter(x_class[:, 0], x_class[:, 1], label=label)\n","\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rr244na0ughZ"},"source":[""],"execution_count":null,"outputs":[]}]}