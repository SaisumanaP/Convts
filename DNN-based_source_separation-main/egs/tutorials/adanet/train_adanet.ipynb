{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_adanet.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xQkWUnVC2t_E","colab_type":"code","colab":{}},"source":["!git clone -b adanet https://github.com/tky823/DNN-based_source_separation.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKSBiUUu2y8g","colab_type":"code","colab":{}},"source":["!pip install soundfile # for Google colaboratory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oK3L1-hc25u2","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRmd-GAT2n9J","colab_type":"text"},"source":["## Make dataset for 2 speakers"]},{"cell_type":"code","metadata":{"id":"3T0lz1Kj2_-G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600042453835,"user_tz":-540,"elapsed":631,"user":{"displayName":"Takuya Hasumi","photoUrl":"","userId":"04699049886341511466"}},"outputId":"d34c90da-70da-4c8f-eeb1-abbb9f274969"},"source":["%cd \"/content/DNN-based_source_separation/egs/librispeech/common\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/DNN-based_source_separation/egs/librispeech/common\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ICZGBABc3B_w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1600042458534,"user_tz":-540,"elapsed":3361,"user":{"displayName":"Takuya Hasumi","photoUrl":"","userId":"04699049886341511466"}},"outputId":"70d8a222-6758-4fec-dbaf-b09f84d76940"},"source":["# !git pull"],"execution_count":2,"outputs":[{"output_type":"stream","text":["remote: Enumerating objects: 28, done.\u001b[K\n","remote: Counting objects:   3% (1/28)\u001b[K\rremote: Counting objects:   7% (2/28)\u001b[K\rremote: Counting objects:  10% (3/28)\u001b[K\rremote: Counting objects:  14% (4/28)\u001b[K\rremote: Counting objects:  17% (5/28)\u001b[K\rremote: Counting objects:  21% (6/28)\u001b[K\rremote: Counting objects:  25% (7/28)\u001b[K\rremote: Counting objects:  28% (8/28)\u001b[K\rremote: Counting objects:  32% (9/28)\u001b[K\rremote: Counting objects:  35% (10/28)\u001b[K\rremote: Counting objects:  39% (11/28)\u001b[K\rremote: Counting objects:  42% (12/28)\u001b[K\rremote: Counting objects:  46% (13/28)\u001b[K\rremote: Counting objects:  50% (14/28)\u001b[K\rremote: Counting objects:  53% (15/28)\u001b[K\rremote: Counting objects:  57% (16/28)\u001b[K\rremote: Counting objects:  60% (17/28)\u001b[K\rremote: Counting objects:  64% (18/28)\u001b[K\rremote: Counting objects:  67% (19/28)\u001b[K\rremote: Counting objects:  71% (20/28)\u001b[K\rremote: Counting objects:  75% (21/28)\u001b[K\rremote: Counting objects:  78% (22/28)\u001b[K\rremote: Counting objects:  82% (23/28)\u001b[K\rremote: Counting objects:  85% (24/28)\u001b[K\rremote: Counting objects:  89% (25/28)\u001b[K\rremote: Counting objects:  92% (26/28)\u001b[K\rremote: Counting objects:  96% (27/28)\u001b[K\rremote: Counting objects: 100% (28/28)\u001b[K\rremote: Counting objects: 100% (28/28), done.\u001b[K\n","remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 18 (delta 9), reused 17 (delta 8), pack-reused 0\u001b[K\n","Unpacking objects:   5% (1/18)   \rUnpacking objects:  11% (2/18)   \rUnpacking objects:  16% (3/18)   \rUnpacking objects:  22% (4/18)   \rUnpacking objects:  27% (5/18)   \rUnpacking objects:  33% (6/18)   \rUnpacking objects:  38% (7/18)   \rUnpacking objects:  44% (8/18)   \rUnpacking objects:  50% (9/18)   \rUnpacking objects:  55% (10/18)   \rUnpacking objects:  61% (11/18)   \rUnpacking objects:  66% (12/18)   \rUnpacking objects:  72% (13/18)   \rUnpacking objects:  77% (14/18)   \rUnpacking objects:  83% (15/18)   \rUnpacking objects:  88% (16/18)   \rUnpacking objects:  94% (17/18)   \rUnpacking objects: 100% (18/18)   \rUnpacking objects: 100% (18/18), done.\n","From https://github.com/tky823/DNN-based_source_separation\n","   02e733f..f6cf4c9  adanet     -> origin/adanet\n","Updating 02e733f..f6cf4c9\n","Fast-forward\n"," egs/librispeech/adanet/local/train.py | 3 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n"," egs/librispeech/adanet/train.sh       | 4 \u001b[32m+\u001b[m\u001b[31m---\u001b[m\n"," egs/librispeech/common/src/driver.py  | 2 \u001b[31m--\u001b[m\n"," 3 files changed, 2 insertions(+), 7 deletions(-)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZzUCwxRD3F-P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1600017081219,"user_tz":-540,"elapsed":646669,"user":{"displayName":"Takuya Hasumi","photoUrl":"","userId":"04699049886341511466"}},"outputId":"63e5583a-8ab3-4e4e-a860-2a9ea066aad3"},"source":["!. ./prepare.sh \"../../../dataset\" 2"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-09-13 17:00:38--  http://www.openslr.org/resources/12/train-clean-100.tar.gz\n","Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n","Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6387309499 (5.9G) [application/x-gzip]\n","Saving to: ‘/tmp/train-clean-100.tar.gz’\n","\n","train-clean-100.tar 100%[===================>]   5.95G  11.4MB/s    in 6m 23s  \n","\n","2020-09-13 17:07:01 (15.9 MB/s) - ‘/tmp/train-clean-100.tar.gz’ saved [6387309499/6387309499]\n","\n","--2020-09-13 17:10:03--  http://www.openslr.org/resources/12/dev-clean.tar.gz\n","Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n","Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 337926286 (322M) [application/x-gzip]\n","Saving to: ‘/tmp/dev-clean.tar.gz’\n","\n","dev-clean.tar.gz    100%[===================>] 322.27M  10.8MB/s    in 24s     \n","\n","2020-09-13 17:10:28 (13.3 MB/s) - ‘/tmp/dev-clean.tar.gz’ saved [337926286/337926286]\n","\n","--2020-09-13 17:10:31--  http://www.openslr.org/resources/12/test-clean.tar.gz\n","Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n","Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 346663984 (331M) [application/x-gzip]\n","Saving to: ‘/tmp/test-clean.tar.gz’\n","\n","test-clean.tar.gz   100%[===================>] 330.60M  13.6MB/s    in 45s     \n","\n","2020-09-13 17:11:17 (7.37 MB/s) - ‘/tmp/test-clean.tar.gz’ saved [346663984/346663984]\n","\n","train-100-2mix.json already exists.\n","valid-2mix.json already exists.\n","test-2mix.json already exists.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nxrO18ed2uSh","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"HPti9ODm3H4m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600017081221,"user_tz":-540,"elapsed":645847,"user":{"displayName":"Takuya Hasumi","photoUrl":"","userId":"04699049886341511466"}},"outputId":"08994640-ff8b-44ca-a864-3422e39fec44"},"source":["%cd \"/content/DNN-based_source_separation/egs/librispeech/adanet\""],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/DNN-based_source_separation/egs/librispeech/adanet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kIAihshLDGKX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c89c4954-9507-4e67-b31f-3243b118317f"},"source":["!. ./train.sh \"/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/adanet/exp\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=4, causal=0, continue_from='', criterion='l2loss', embed_dim=20, epochs=100, fft_size=256, hidden_channels=256, hop_size=64, ideal_mask='ibm', loss_dir='/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/adanet/exp/2mix/l2loss/stft256-64_hamming-window_ibm_threshold40/K20_H256_B4_N6_causal0_mask-sigmoid/b4_e100_rmsprop-lr1e-4-decay0/seed111/loss', lr=0.0001, mask_nonlinear='sigmoid', max_norm=None, model_dir='/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/adanet/exp/2mix/l2loss/stft256-64_hamming-window_ibm_threshold40/K20_H256_B4_N6_causal0_mask-sigmoid/b4_e100_rmsprop-lr1e-4-decay0/seed111/model', n_anchors=6, n_sources=2, num_blocks=4, optimizer='rmsprop', overwrite=0, sample_dir='/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/adanet/exp/2mix/l2loss/stft256-64_hamming-window_ibm_threshold40/K20_H256_B4_N6_causal0_mask-sigmoid/b4_e100_rmsprop-lr1e-4-decay0/seed111/sample', seed=111, sr=16000, threshold=40.0, train_json_path='../../../dataset/LibriSpeech/train-clean-100/train-100-2mix.json', use_cuda=1, valid_json_path='../../../dataset/LibriSpeech/dev-clean/valid-2mix.json', wav_root='../../../dataset/LibriSpeech', weight_decay=0.0, window_fn='hamming')\n","Training dataset includes 83256 samples.\n","Valid dataset includes 83256 samples.\n","ADANet(\n","  (lstm): StackedLSTM(\n","    (net): Sequential(\n","      (0): LSTM(129, 128, batch_first=True, bidirectional=True)\n","      (1): LSTM(256, 128, batch_first=True, bidirectional=True)\n","      (2): LSTM(256, 128, batch_first=True, bidirectional=True)\n","      (3): LSTM(256, 128, batch_first=True, bidirectional=True)\n","    )\n","  )\n","  (fc): Linear(in_features=256, out_features=2580, bias=True)\n","  (mask_nonlinear2d): Sigmoid()\n",")\n","# Parameters: 2114068\n","Use CUDA\n","[Epoch 1/100] iter 100/20814 loss: 88.06033\n","[Epoch 1/100] iter 200/20814 loss: 97.91776\n","[Epoch 1/100] iter 300/20814 loss: 103.39133\n","[Epoch 1/100] iter 400/20814 loss: 91.91707\n","[Epoch 1/100] iter 500/20814 loss: 72.47845\n","[Epoch 1/100] iter 600/20814 loss: 91.98311\n","[Epoch 1/100] iter 700/20814 loss: 120.74029\n","[Epoch 1/100] iter 800/20814 loss: 82.79013\n","[Epoch 1/100] iter 900/20814 loss: 109.19644\n","[Epoch 1/100] iter 1000/20814 loss: 84.85365\n","[Epoch 1/100] iter 1100/20814 loss: 103.75305\n","[Epoch 1/100] iter 1200/20814 loss: 95.46883\n","[Epoch 1/100] iter 1300/20814 loss: 92.13669\n","[Epoch 1/100] iter 1400/20814 loss: 92.69691\n","[Epoch 1/100] iter 1500/20814 loss: 68.02707\n","[Epoch 1/100] iter 1600/20814 loss: 99.56741\n","[Epoch 1/100] iter 1700/20814 loss: 97.45879\n","[Epoch 1/100] iter 1800/20814 loss: 108.00235\n","[Epoch 1/100] iter 1900/20814 loss: 104.30470\n","[Epoch 1/100] iter 2000/20814 loss: 101.31891\n","[Epoch 1/100] iter 2100/20814 loss: 104.34650\n","[Epoch 1/100] iter 2200/20814 loss: 91.62286\n","[Epoch 1/100] iter 2300/20814 loss: 127.44090\n","[Epoch 1/100] iter 2400/20814 loss: 98.97855\n","[Epoch 1/100] iter 2500/20814 loss: 115.05402\n","[Epoch 1/100] iter 2600/20814 loss: 101.75070\n","[Epoch 1/100] iter 2700/20814 loss: 101.93285\n","[Epoch 1/100] iter 2800/20814 loss: 130.67010\n","[Epoch 1/100] iter 2900/20814 loss: 102.91687\n","[Epoch 1/100] iter 3000/20814 loss: 77.27139\n","[Epoch 1/100] iter 3100/20814 loss: 98.54328\n","[Epoch 1/100] iter 3200/20814 loss: 105.80380\n","[Epoch 1/100] iter 3300/20814 loss: 83.80775\n","[Epoch 1/100] iter 3400/20814 loss: 109.57743\n","[Epoch 1/100] iter 3500/20814 loss: 94.55591\n","[Epoch 1/100] iter 3600/20814 loss: 116.36926\n","[Epoch 1/100] iter 3700/20814 loss: 118.98010\n","[Epoch 1/100] iter 3800/20814 loss: 115.69742\n","[Epoch 1/100] iter 3900/20814 loss: 135.78384\n","[Epoch 1/100] iter 4000/20814 loss: 82.98352\n","[Epoch 1/100] iter 4100/20814 loss: 176.17593\n","[Epoch 1/100] iter 4200/20814 loss: 102.77023\n","[Epoch 1/100] iter 4300/20814 loss: 100.89963\n","[Epoch 1/100] iter 4400/20814 loss: 84.49826\n","[Epoch 1/100] iter 4500/20814 loss: 111.40826\n","[Epoch 1/100] iter 4600/20814 loss: 110.41567\n","[Epoch 1/100] iter 4700/20814 loss: 96.40967\n","[Epoch 1/100] iter 4800/20814 loss: 85.09563\n","[Epoch 1/100] iter 4900/20814 loss: 88.02367\n","[Epoch 1/100] iter 5000/20814 loss: 79.70143\n","[Epoch 1/100] iter 5100/20814 loss: 121.04118\n","[Epoch 1/100] iter 5200/20814 loss: 105.69559\n","[Epoch 1/100] iter 5300/20814 loss: 92.84882\n","[Epoch 1/100] iter 5400/20814 loss: 111.35378\n","[Epoch 1/100] iter 5500/20814 loss: 89.81407\n","[Epoch 1/100] iter 5600/20814 loss: 103.47409\n","[Epoch 1/100] iter 5700/20814 loss: 82.86852\n","[Epoch 1/100] iter 5800/20814 loss: 105.23575\n","[Epoch 1/100] iter 5900/20814 loss: 119.44766\n","[Epoch 1/100] iter 6000/20814 loss: 77.06740\n","[Epoch 1/100] iter 6100/20814 loss: 93.42716\n","[Epoch 1/100] iter 6200/20814 loss: 82.96254\n","[Epoch 1/100] iter 6300/20814 loss: 101.46954\n","[Epoch 1/100] iter 6400/20814 loss: 116.91071\n","[Epoch 1/100] iter 6500/20814 loss: 109.35526\n","[Epoch 1/100] iter 6600/20814 loss: 77.86983\n","[Epoch 1/100] iter 6700/20814 loss: 100.69691\n","[Epoch 1/100] iter 6800/20814 loss: 88.86079\n","[Epoch 1/100] iter 6900/20814 loss: 92.52219\n","[Epoch 1/100] iter 7000/20814 loss: 112.98390\n","[Epoch 1/100] iter 7100/20814 loss: 161.69728\n","[Epoch 1/100] iter 7200/20814 loss: 88.88058\n","[Epoch 1/100] iter 7300/20814 loss: 122.16286\n","[Epoch 1/100] iter 7400/20814 loss: 84.16843\n","[Epoch 1/100] iter 7500/20814 loss: 74.07284\n","[Epoch 1/100] iter 7600/20814 loss: 84.61382\n","[Epoch 1/100] iter 7700/20814 loss: 86.03998\n","[Epoch 1/100] iter 7800/20814 loss: 90.95895\n","[Epoch 1/100] iter 7900/20814 loss: 101.98265\n","[Epoch 1/100] iter 8000/20814 loss: 118.67133\n","[Epoch 1/100] iter 8100/20814 loss: 79.11606\n","[Epoch 1/100] iter 8200/20814 loss: 93.93155\n","[Epoch 1/100] iter 8300/20814 loss: 77.66151\n","[Epoch 1/100] iter 8400/20814 loss: 93.35881\n","[Epoch 1/100] iter 8500/20814 loss: 123.70598\n","[Epoch 1/100] iter 8600/20814 loss: 64.93105\n","[Epoch 1/100] iter 8700/20814 loss: 95.10361\n","[Epoch 1/100] iter 8800/20814 loss: 95.87698\n","[Epoch 1/100] iter 8900/20814 loss: 91.82677\n","[Epoch 1/100] iter 9000/20814 loss: 108.93079\n","[Epoch 1/100] iter 9100/20814 loss: 121.74684\n","[Epoch 1/100] iter 9200/20814 loss: 128.41100\n","[Epoch 1/100] iter 9300/20814 loss: 67.50446\n","[Epoch 1/100] iter 9400/20814 loss: 81.18402\n","[Epoch 1/100] iter 9500/20814 loss: 107.84219\n","[Epoch 1/100] iter 9600/20814 loss: 91.41351\n","[Epoch 1/100] iter 9700/20814 loss: 80.39120\n","[Epoch 1/100] iter 9800/20814 loss: 139.04675\n","[Epoch 1/100] iter 9900/20814 loss: 55.69308\n","[Epoch 1/100] iter 10000/20814 loss: 85.32678\n","[Epoch 1/100] iter 10100/20814 loss: 98.12080\n","[Epoch 1/100] iter 10200/20814 loss: 95.81418\n","[Epoch 1/100] iter 10300/20814 loss: 111.26927\n","[Epoch 1/100] iter 10400/20814 loss: 107.77448\n","[Epoch 1/100] iter 10500/20814 loss: 136.82454\n","[Epoch 1/100] iter 10600/20814 loss: 95.73025\n","[Epoch 1/100] iter 10700/20814 loss: 79.02670\n","[Epoch 1/100] iter 10800/20814 loss: 94.47366\n","[Epoch 1/100] iter 10900/20814 loss: 112.34577\n","[Epoch 1/100] iter 11000/20814 loss: 92.07311\n","[Epoch 1/100] iter 11100/20814 loss: 92.76552\n","[Epoch 1/100] iter 11200/20814 loss: 83.72114\n","[Epoch 1/100] iter 11300/20814 loss: 102.58934\n","[Epoch 1/100] iter 11400/20814 loss: 100.57892\n","[Epoch 1/100] iter 11500/20814 loss: 75.03463\n","[Epoch 1/100] iter 11600/20814 loss: 102.25763\n","[Epoch 1/100] iter 11700/20814 loss: 107.84296\n","[Epoch 1/100] iter 11800/20814 loss: 75.52869\n","[Epoch 1/100] iter 11900/20814 loss: 83.28233\n","[Epoch 1/100] iter 12000/20814 loss: 104.88133\n","[Epoch 1/100] iter 12100/20814 loss: 103.76772\n","[Epoch 1/100] iter 12200/20814 loss: 122.80173\n","[Epoch 1/100] iter 12300/20814 loss: 96.55616\n","[Epoch 1/100] iter 12400/20814 loss: 93.40270\n","[Epoch 1/100] iter 12500/20814 loss: 101.66819\n","[Epoch 1/100] iter 12600/20814 loss: 140.66719\n","[Epoch 1/100] iter 12700/20814 loss: 101.27601\n","[Epoch 1/100] iter 12800/20814 loss: 63.28215\n","[Epoch 1/100] iter 12900/20814 loss: 78.88807\n","[Epoch 1/100] iter 13000/20814 loss: 96.25447\n","[Epoch 1/100] iter 13100/20814 loss: 94.66196\n","[Epoch 1/100] iter 13200/20814 loss: 102.60425\n","[Epoch 1/100] iter 13300/20814 loss: 85.37840\n","[Epoch 1/100] iter 13400/20814 loss: 159.73383\n","[Epoch 1/100] iter 13500/20814 loss: 113.42169\n","[Epoch 1/100] iter 13600/20814 loss: 100.61623\n","[Epoch 1/100] iter 13700/20814 loss: 98.46739\n","[Epoch 1/100] iter 13800/20814 loss: 101.76482\n","[Epoch 1/100] iter 13900/20814 loss: 93.04350\n","[Epoch 1/100] iter 14000/20814 loss: 149.20160\n","[Epoch 1/100] iter 14100/20814 loss: 86.04567\n","[Epoch 1/100] iter 14200/20814 loss: 97.07686\n","[Epoch 1/100] iter 14300/20814 loss: 113.01839\n","[Epoch 1/100] iter 14400/20814 loss: 97.89575\n","[Epoch 1/100] iter 14500/20814 loss: 80.65442\n","[Epoch 1/100] iter 14600/20814 loss: 89.15311\n","[Epoch 1/100] iter 14700/20814 loss: 76.93232\n","[Epoch 1/100] iter 14800/20814 loss: 92.36736\n","[Epoch 1/100] iter 14900/20814 loss: 108.74293\n","[Epoch 1/100] iter 15000/20814 loss: 120.72870\n","[Epoch 1/100] iter 15100/20814 loss: 98.62048\n","[Epoch 1/100] iter 15200/20814 loss: 98.64084\n","[Epoch 1/100] iter 15300/20814 loss: 83.30388\n","[Epoch 1/100] iter 15400/20814 loss: 107.41232\n","[Epoch 1/100] iter 15500/20814 loss: 102.60590\n","[Epoch 1/100] iter 15600/20814 loss: 95.97424\n","[Epoch 1/100] iter 15700/20814 loss: 98.48976\n","[Epoch 1/100] iter 15800/20814 loss: 105.53995\n","[Epoch 1/100] iter 15900/20814 loss: 105.69109\n","[Epoch 1/100] iter 16000/20814 loss: 89.28865\n","[Epoch 1/100] iter 16100/20814 loss: 96.39135\n","[Epoch 1/100] iter 16200/20814 loss: 93.78832\n","[Epoch 1/100] iter 16300/20814 loss: 79.77769\n","[Epoch 1/100] iter 16400/20814 loss: 96.45740\n","[Epoch 1/100] iter 16500/20814 loss: 89.35274\n","[Epoch 1/100] iter 16600/20814 loss: 99.81660\n","[Epoch 1/100] iter 16700/20814 loss: 92.35146\n","[Epoch 1/100] iter 16800/20814 loss: 97.67923\n","[Epoch 1/100] iter 16900/20814 loss: 89.73196\n","[Epoch 1/100] iter 17000/20814 loss: 79.47945\n","[Epoch 1/100] iter 17100/20814 loss: 106.59885\n","[Epoch 1/100] iter 17200/20814 loss: 87.33679\n","[Epoch 1/100] iter 17300/20814 loss: 101.19307\n","[Epoch 1/100] iter 17400/20814 loss: 101.43118\n","[Epoch 1/100] iter 17500/20814 loss: 93.67345\n","[Epoch 1/100] iter 17600/20814 loss: 91.54889\n","[Epoch 1/100] iter 17700/20814 loss: 107.60726\n","[Epoch 1/100] iter 17800/20814 loss: 139.53983\n","[Epoch 1/100] iter 17900/20814 loss: 88.40865\n","[Epoch 1/100] iter 18000/20814 loss: 87.11854\n","[Epoch 1/100] iter 18100/20814 loss: 92.29179\n","[Epoch 1/100] iter 18200/20814 loss: 97.80463\n","[Epoch 1/100] iter 18300/20814 loss: 80.40965\n","[Epoch 1/100] iter 18400/20814 loss: 89.34755\n","[Epoch 1/100] iter 18500/20814 loss: 90.61266\n","[Epoch 1/100] iter 18600/20814 loss: 74.31430\n","[Epoch 1/100] iter 18700/20814 loss: 111.89217\n","[Epoch 1/100] iter 18800/20814 loss: 98.12146\n","[Epoch 1/100] iter 18900/20814 loss: 96.27412\n","[Epoch 1/100] iter 19000/20814 loss: 104.84434\n","[Epoch 1/100] iter 19100/20814 loss: 106.63400\n","[Epoch 1/100] iter 19200/20814 loss: 108.82291\n","[Epoch 1/100] iter 19300/20814 loss: 86.93324\n","[Epoch 1/100] iter 19400/20814 loss: 111.76872\n","[Epoch 1/100] iter 19500/20814 loss: 103.00075\n","[Epoch 1/100] iter 19600/20814 loss: 119.89698\n","[Epoch 1/100] iter 19700/20814 loss: 168.93881\n","[Epoch 1/100] iter 19800/20814 loss: 89.31769\n","[Epoch 1/100] iter 19900/20814 loss: 93.82236\n","[Epoch 1/100] iter 20000/20814 loss: 84.61787\n","[Epoch 1/100] iter 20100/20814 loss: 78.14062\n","[Epoch 1/100] iter 20200/20814 loss: 83.15088\n","[Epoch 1/100] iter 20300/20814 loss: 100.88028\n","[Epoch 1/100] iter 20400/20814 loss: 105.49089\n","[Epoch 1/100] iter 20500/20814 loss: 123.08794\n","[Epoch 1/100] iter 20600/20814 loss: 112.17683\n","[Epoch 1/100] iter 20700/20814 loss: 123.62202\n","[Epoch 1/100] iter 20800/20814 loss: 105.72159\n","[Epoch 1/100] loss (train): 100.31109, loss (valid): 99.77989, 16353.541 [sec]\n","[Epoch 2/100] iter 100/20814 loss: 96.91102\n","[Epoch 2/100] iter 200/20814 loss: 71.33237\n","[Epoch 2/100] iter 300/20814 loss: 126.38868\n","[Epoch 2/100] iter 400/20814 loss: 71.46327\n","[Epoch 2/100] iter 500/20814 loss: 89.20971\n","[Epoch 2/100] iter 600/20814 loss: 116.31794\n","[Epoch 2/100] iter 700/20814 loss: 90.98395\n","[Epoch 2/100] iter 800/20814 loss: 102.42218\n","[Epoch 2/100] iter 900/20814 loss: 85.00603\n","[Epoch 2/100] iter 1000/20814 loss: 96.18156\n","[Epoch 2/100] iter 1100/20814 loss: 108.07741\n","[Epoch 2/100] iter 1200/20814 loss: 105.49622\n","[Epoch 2/100] iter 1300/20814 loss: 67.71671\n","[Epoch 2/100] iter 1400/20814 loss: 110.71189\n","[Epoch 2/100] iter 1500/20814 loss: 87.28193\n","[Epoch 2/100] iter 1600/20814 loss: 119.95561\n","[Epoch 2/100] iter 1700/20814 loss: 106.86705\n","[Epoch 2/100] iter 1800/20814 loss: 88.68810\n","[Epoch 2/100] iter 1900/20814 loss: 89.32158\n","[Epoch 2/100] iter 2000/20814 loss: 110.22354\n","[Epoch 2/100] iter 2100/20814 loss: 104.21711\n","[Epoch 2/100] iter 2200/20814 loss: 137.19836\n","[Epoch 2/100] iter 2300/20814 loss: 174.05354\n","[Epoch 2/100] iter 2400/20814 loss: 96.90817\n","[Epoch 2/100] iter 2500/20814 loss: 102.05755\n","[Epoch 2/100] iter 2600/20814 loss: 78.40303\n","[Epoch 2/100] iter 2700/20814 loss: 112.97606\n","[Epoch 2/100] iter 2800/20814 loss: 85.29645\n","[Epoch 2/100] iter 2900/20814 loss: 96.43600\n","[Epoch 2/100] iter 3000/20814 loss: 102.86017\n","[Epoch 2/100] iter 3100/20814 loss: 89.19057\n","[Epoch 2/100] iter 3200/20814 loss: 87.22915\n","[Epoch 2/100] iter 3300/20814 loss: 101.29430\n","[Epoch 2/100] iter 3400/20814 loss: 85.72462\n","[Epoch 2/100] iter 3500/20814 loss: 109.11506\n","[Epoch 2/100] iter 3600/20814 loss: 75.28169\n","[Epoch 2/100] iter 3700/20814 loss: 96.87933\n","[Epoch 2/100] iter 3800/20814 loss: 97.70963\n","[Epoch 2/100] iter 3900/20814 loss: 92.50817\n","[Epoch 2/100] iter 4000/20814 loss: 116.04675\n","[Epoch 2/100] iter 4100/20814 loss: 82.64648\n","[Epoch 2/100] iter 4200/20814 loss: 84.87661\n","[Epoch 2/100] iter 4300/20814 loss: 106.52400\n","[Epoch 2/100] iter 4400/20814 loss: 89.22797\n","[Epoch 2/100] iter 4500/20814 loss: 111.19655\n","[Epoch 2/100] iter 4600/20814 loss: 110.35748\n","[Epoch 2/100] iter 4700/20814 loss: 87.96419\n","[Epoch 2/100] iter 4800/20814 loss: 88.51313\n","[Epoch 2/100] iter 4900/20814 loss: 90.71091\n","[Epoch 2/100] iter 5000/20814 loss: 113.63011\n","[Epoch 2/100] iter 5100/20814 loss: 111.48737\n","[Epoch 2/100] iter 5200/20814 loss: 86.28874\n","[Epoch 2/100] iter 5300/20814 loss: 82.69469\n","[Epoch 2/100] iter 5400/20814 loss: 104.67255\n","[Epoch 2/100] iter 5500/20814 loss: 100.32195\n","[Epoch 2/100] iter 5600/20814 loss: 102.60918\n","[Epoch 2/100] iter 5700/20814 loss: 98.40865\n","[Epoch 2/100] iter 5800/20814 loss: 87.03271\n","[Epoch 2/100] iter 5900/20814 loss: 120.88031\n","[Epoch 2/100] iter 6000/20814 loss: 82.98682\n","[Epoch 2/100] iter 6100/20814 loss: 93.31303\n","[Epoch 2/100] iter 6200/20814 loss: 96.78281\n","[Epoch 2/100] iter 6300/20814 loss: 75.45195\n","[Epoch 2/100] iter 6400/20814 loss: 113.70364\n","[Epoch 2/100] iter 6500/20814 loss: 107.99792\n","[Epoch 2/100] iter 6600/20814 loss: 87.41388\n","[Epoch 2/100] iter 6700/20814 loss: 108.60886\n","[Epoch 2/100] iter 6800/20814 loss: 76.22670\n","[Epoch 2/100] iter 6900/20814 loss: 113.71098\n","[Epoch 2/100] iter 7000/20814 loss: 84.62082\n","[Epoch 2/100] iter 7100/20814 loss: 94.45129\n","[Epoch 2/100] iter 7200/20814 loss: 101.26072\n","[Epoch 2/100] iter 7300/20814 loss: 165.68573\n","[Epoch 2/100] iter 7400/20814 loss: 113.86042\n","[Epoch 2/100] iter 7500/20814 loss: 111.11694\n","[Epoch 2/100] iter 7600/20814 loss: 99.58807\n","[Epoch 2/100] iter 7700/20814 loss: 92.45874\n","[Epoch 2/100] iter 7800/20814 loss: 85.52972\n","[Epoch 2/100] iter 7900/20814 loss: 74.08770\n","[Epoch 2/100] iter 8000/20814 loss: 96.53983\n","[Epoch 2/100] iter 8100/20814 loss: 84.09742\n","[Epoch 2/100] iter 8200/20814 loss: 77.38190\n","[Epoch 2/100] iter 8300/20814 loss: 90.80585\n","[Epoch 2/100] iter 8400/20814 loss: 92.82652\n","[Epoch 2/100] iter 8500/20814 loss: 95.59093\n","[Epoch 2/100] iter 8600/20814 loss: 81.02448\n","[Epoch 2/100] iter 8700/20814 loss: 91.32079\n","[Epoch 2/100] iter 8800/20814 loss: 100.86752\n","[Epoch 2/100] iter 8900/20814 loss: 91.85806\n","[Epoch 2/100] iter 9000/20814 loss: 89.65146\n","[Epoch 2/100] iter 9100/20814 loss: 84.05534\n","[Epoch 2/100] iter 9200/20814 loss: 156.29855\n","[Epoch 2/100] iter 9300/20814 loss: 140.17874\n","[Epoch 2/100] iter 9400/20814 loss: 111.22919\n","[Epoch 2/100] iter 9500/20814 loss: 104.96207\n","[Epoch 2/100] iter 9600/20814 loss: 100.10747\n","[Epoch 2/100] iter 9700/20814 loss: 86.94051\n","[Epoch 2/100] iter 9800/20814 loss: 87.09528\n","[Epoch 2/100] iter 9900/20814 loss: 105.31450\n","[Epoch 2/100] iter 10000/20814 loss: 106.31476\n","[Epoch 2/100] iter 10100/20814 loss: 106.71502\n","[Epoch 2/100] iter 10200/20814 loss: 127.61997\n","[Epoch 2/100] iter 10300/20814 loss: 108.83484\n","[Epoch 2/100] iter 10400/20814 loss: 87.60217\n","[Epoch 2/100] iter 10500/20814 loss: 106.79597\n","[Epoch 2/100] iter 10600/20814 loss: 102.54521\n","[Epoch 2/100] iter 10700/20814 loss: 95.13655\n","[Epoch 2/100] iter 10800/20814 loss: 110.58919\n","[Epoch 2/100] iter 10900/20814 loss: 156.55533\n","[Epoch 2/100] iter 11000/20814 loss: 91.64604\n","[Epoch 2/100] iter 11100/20814 loss: 86.25620\n","[Epoch 2/100] iter 11200/20814 loss: 97.77994\n","[Epoch 2/100] iter 11300/20814 loss: 92.60008\n","[Epoch 2/100] iter 11400/20814 loss: 118.94119\n","[Epoch 2/100] iter 11500/20814 loss: 86.82680\n","[Epoch 2/100] iter 11600/20814 loss: 100.00813\n","[Epoch 2/100] iter 11700/20814 loss: 98.12921\n","[Epoch 2/100] iter 11800/20814 loss: 95.47435\n","[Epoch 2/100] iter 11900/20814 loss: 70.92752\n","[Epoch 2/100] iter 12000/20814 loss: 100.39154\n","[Epoch 2/100] iter 12100/20814 loss: 87.96040\n","[Epoch 2/100] iter 12200/20814 loss: 108.90750\n","[Epoch 2/100] iter 12300/20814 loss: 104.21281\n","[Epoch 2/100] iter 12400/20814 loss: 96.33776\n","[Epoch 2/100] iter 12500/20814 loss: 93.23621\n","[Epoch 2/100] iter 12600/20814 loss: 97.67678\n","[Epoch 2/100] iter 12700/20814 loss: 124.96139\n","[Epoch 2/100] iter 12800/20814 loss: 105.45186\n","[Epoch 2/100] iter 12900/20814 loss: 97.70499\n","[Epoch 2/100] iter 13000/20814 loss: 87.08117\n","[Epoch 2/100] iter 13100/20814 loss: 101.45198\n","[Epoch 2/100] iter 13200/20814 loss: 91.48441\n","[Epoch 2/100] iter 13300/20814 loss: 102.71336\n","[Epoch 2/100] iter 13400/20814 loss: 93.27478\n","[Epoch 2/100] iter 13500/20814 loss: 85.13432\n","[Epoch 2/100] iter 13600/20814 loss: 90.97889\n","[Epoch 2/100] iter 13700/20814 loss: 90.99525\n","[Epoch 2/100] iter 13800/20814 loss: 101.96514\n","[Epoch 2/100] iter 13900/20814 loss: 77.53093\n","[Epoch 2/100] iter 14000/20814 loss: 123.90251\n","[Epoch 2/100] iter 14100/20814 loss: 92.10322\n","[Epoch 2/100] iter 14200/20814 loss: 78.80383\n","[Epoch 2/100] iter 14300/20814 loss: 103.60007\n","[Epoch 2/100] iter 14400/20814 loss: 154.70570\n","[Epoch 2/100] iter 14500/20814 loss: 100.97699\n","[Epoch 2/100] iter 14600/20814 loss: 103.52528\n","[Epoch 2/100] iter 14700/20814 loss: 80.30585\n","[Epoch 2/100] iter 14800/20814 loss: 137.36282\n","[Epoch 2/100] iter 14900/20814 loss: 102.42500\n","[Epoch 2/100] iter 15000/20814 loss: 98.45910\n","[Epoch 2/100] iter 15100/20814 loss: 101.69650\n","[Epoch 2/100] iter 15200/20814 loss: 133.66769\n","[Epoch 2/100] iter 15300/20814 loss: 96.25043\n","[Epoch 2/100] iter 15400/20814 loss: 93.92158\n","[Epoch 2/100] iter 15500/20814 loss: 118.45657\n","[Epoch 2/100] iter 15600/20814 loss: 93.34340\n","[Epoch 2/100] iter 15700/20814 loss: 104.96796\n","[Epoch 2/100] iter 15800/20814 loss: 125.46910\n","[Epoch 2/100] iter 15900/20814 loss: 107.17850\n","[Epoch 2/100] iter 16000/20814 loss: 120.02541\n","[Epoch 2/100] iter 16100/20814 loss: 68.71323\n","[Epoch 2/100] iter 16200/20814 loss: 88.16072\n","[Epoch 2/100] iter 16300/20814 loss: 70.89967\n","[Epoch 2/100] iter 16400/20814 loss: 163.70448\n","[Epoch 2/100] iter 16500/20814 loss: 103.20603\n","[Epoch 2/100] iter 16600/20814 loss: 99.91184\n","[Epoch 2/100] iter 16700/20814 loss: 92.31212\n","[Epoch 2/100] iter 16800/20814 loss: 90.00282\n","[Epoch 2/100] iter 16900/20814 loss: 87.41518\n","[Epoch 2/100] iter 17000/20814 loss: 76.78764\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"78glLv3W2x5W","colab_type":"text"},"source":["## ResumeTraining"]},{"cell_type":"code","metadata":{"id":"W3vD0CLjupgD","colab_type":"code","colab":{}},"source":["# path = \"/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/danet/exp/2mix/l2loss/stft256-64_hamming-window_ibm_threshold10/K20_H256_B4_causal0_mask-sigmoid/b4_e100_rmsprop-lr1e-4-decay0/seed111/model/last.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2HXuEGVuy0Q","colab_type":"code","colab":{}},"source":["# !. ./train.sh \"/content/drive/My Drive/Colab Notebooks/work/DNN-based_source_separation/egs/librispeech/danet/exp\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5jTMuMrSPIV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}