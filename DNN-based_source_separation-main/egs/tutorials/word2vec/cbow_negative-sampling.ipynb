{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cbow_negative-sampling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMVIfTXRb7oYL6wff6+6+Ri"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Word2Vec using CBoW with negative sampling"],"metadata":{"id":"TLy1WPywSxLU"}},{"cell_type":"markdown","source":["References:\n","- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)\n","- [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)"],"metadata":{"id":"NwULeluwLm8s"}},{"cell_type":"code","source":["%%bash\n","git clone https://github.com/tky823/DNN-based_source_separation.git"],"metadata":{"id":"BEtb__JtCOgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AagZIJljmldY"},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","import random\n","from functools import partial"]},{"cell_type":"code","source":["sys.path.append(\"/content/DNN-based_source_separation/egs/tutorials/word2vec/src\")"],"metadata":{"id":"yTX8vCCYClDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"kd4Vi8-MP3ON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams[\"figure.dpi\"] = 100"],"metadata":{"id":"_PPU3cbLP5mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"N5Goa5-JnKcN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchtext\n","from torchtext.data import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer"],"metadata":{"id":"Na-it9zHnLcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from adhoc_utils import build_vocab, build_neg_freq, build_neg_table\n","from adhoc_criterion import NegativeSamplingLoss\n","from adhoc_driver import Trainer"],"metadata":{"id":"JZB2WgPLDwzk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn_freq(batch, text_pipeline, neg_freq, context_size=4, num_neg_samples=20, max_seq_length=256):\n","    assert type(neg_freq) is list\n","\n","    neg_samples = torch.arange(len(neg_freq)) # Includes all word IDs\n","    batch_input, batch_pos, batch_neg = [], [], []\n","    for text in batch:\n","        text_tokens_ids = text_pipeline(text)\n","        raw_seq_length = len(text_tokens_ids)\n","\n","        if raw_seq_length < 2 * context_size + 1:\n","            continue\n","\n","        if max_seq_length is not None:\n","            _max_seq_length = min(max_seq_length, raw_seq_length)\n","            high = max(0, raw_seq_length - _max_seq_length)\n","            start_idx = torch.randint(0, high+1, ())\n","            end_idx = start_idx + _max_seq_length\n","            text_tokens_ids = text_tokens_ids[start_idx: end_idx]\n","            seq_length = len(text_tokens_ids)\n","        else:\n","            seq_length = raw_seq_length\n","\n","        for start_idx in range(seq_length - 2 * context_size):\n","            end_idx = start_idx + 2 * context_size + 1\n","            token_id_sequence = text_tokens_ids[start_idx: end_idx]\n","            pos = token_id_sequence.pop(context_size)\n","            input = token_id_sequence\n","\n","            # nagative sampling\n","            tmp = neg_freq[pos]\n","            neg_freq[pos] = 0\n","            neg = random.choices(neg_samples, k=num_neg_samples, weights=neg_freq)\n","            neg_freq[pos] = tmp\n","\n","            batch_input.append(input)\n","            batch_pos.append(pos)\n","            batch_neg.append(neg)\n","\n","    batch_input = torch.tensor(batch_input, dtype=torch.long) # (num_samples, 2 * context_size)\n","    batch_pos = torch.tensor(batch_pos, dtype=torch.long) # (num_samples,)\n","    batch_neg = torch.tensor(batch_neg, dtype=torch.long) # (num_samples, num_neg_samples)\n","\n","    return batch_input, batch_pos, batch_neg\n","\n","def collate_fn_table(batch, text_pipeline, neg_table, context_size=4, num_neg_samples=20, max_seq_length=256):\n","    distr_table = neg_table[\"distr\"]\n","    start_table = neg_table[\"start\"]\n","    count_table = neg_table[\"count\"]\n","\n","    assert isinstance(distr_table, torch.Tensor) and isinstance(start_table, torch.Tensor) and isinstance(count_table, torch.Tensor)\n","\n","    neg_table_size = len(distr_table)\n","    batch_input, batch_pos, batch_neg = [], [], []\n","\n","    for text in batch:\n","        text_tokens_ids = text_pipeline(text)\n","        raw_seq_length = len(text_tokens_ids)\n","\n","        if raw_seq_length < 2 * context_size + 1:\n","            continue\n","\n","        if max_seq_length is not None:\n","            _max_seq_length = min(max_seq_length, raw_seq_length)\n","            high = max(0, raw_seq_length - _max_seq_length)\n","            start_idx = torch.randint(0, high+1, ())\n","            end_idx = start_idx + _max_seq_length\n","            text_tokens_ids = text_tokens_ids[start_idx: end_idx]\n","            seq_length = len(text_tokens_ids)\n","        else:\n","            seq_length = raw_seq_length\n","\n","        for start_idx in range(seq_length - 2 * context_size):\n","            end_idx = start_idx + 2 * context_size + 1\n","            token_id_sequence = text_tokens_ids[start_idx: end_idx]\n","            pos = token_id_sequence.pop(context_size)\n","            input = token_id_sequence\n","\n","            # nagative sampling\n","            pos = torch.tensor(pos, dtype=torch.long)\n","            start = start_table[pos]\n","            count = count_table[pos]\n","            \n","            table_ids = torch.randint(0, neg_table_size - count, (num_neg_samples,))\n","            table_ids = torch.where(table_ids >= start, table_ids + count, table_ids)\n","            neg = distr_table[table_ids].tolist()\n","\n","            batch_input.append(input)\n","            batch_pos.append(pos)\n","            batch_neg.append(neg)\n","\n","    batch_input = torch.tensor(batch_input, dtype=torch.long) # (num_samples, 2 * context_size)\n","    batch_pos = torch.tensor(batch_pos, dtype=torch.long) # (num_samples,)\n","    batch_neg = torch.tensor(batch_neg, dtype=torch.long) # (num_samples, num_neg_samples)\n","\n","    return batch_input, batch_pos, batch_neg"],"metadata":{"id":"AemZRqa-n1HX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CBoWNegativeSampling(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, max_norm=1, eps=1e-12):\n","        super().__init__()\n","\n","        self.vocab_size, self.embed_dim = vocab_size, embed_dim\n","        self.max_norm = max_norm\n","        self.eps = eps\n","\n","        self.enc_embedding = nn.Embedding(vocab_size, embed_dim, max_norm=max_norm)\n","        self.dec_embedding = nn.Embedding(vocab_size, embed_dim)\n","\n","    def forward(self, input, pos=None, neg=None):\n","        \"\"\"\n","        Args:\n","            input: (batch_size, 2 * context_size)\n","            pos: (batch_size,)\n","            neg: (batch_size, num_neg_samples)\n","        Returns:\n","            output: (batch_size, embed_dim)\n","            pos_output: (batch_size, embed_dim)\n","            neg_output: (batch_size, num_neg_samples, embed_dim)\n","        \"\"\"\n","        output = self.embed(input)\n","\n","        if pos is None and neg is None:\n","            return output\n","\n","        if pos is None or neg is None:\n","            raise ValueError(\"Specify pos and neg.\")\n","\n","        pos_output = self.dec_embedding(pos) # (batch_size, embed_dim)\n","        neg_output = self.dec_embedding(neg) # (batch_size, num_neg_samples, embed_dim)\n","\n","        return output, pos_output, neg_output\n","\n","    def embed(self, input, normalized=False):\n","        \"\"\"\n","        Args:\n","            input: (batch_size, 2 * context_size)\n","        Returns:\n","            output: (batch_size, embed_dim)\n","        \"\"\"\n","        output = self.enc_embedding(input)\n","        output = output.mean(dim=1)\n","\n","        if normalized:\n","            output = F.normalize(output, dim=1, eps=self.eps) # (batch_size, embed_dim)\n","        \n","        return output\n","\n","    def get_embedding_weights(self):\n","        \"\"\"\n","        Returns:\n","            weights: (vocab_size, embed_dim)\n","        \"\"\"\n","        max_norm = self.max_norm\n","\n","        weights = self.enc_embedding.weight.data\n","        norm = torch.linalg.vector_norm(weights, dim=1, keepdim=True) # (vocab_size, 1)\n","        weights = torch.where(norm > max_norm, max_norm * weights / norm, weights)\n","\n","        return weights"],"metadata":{"id":"a6duDtQBn3MV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AdhocTrainer(Trainer):\n","    def __init__(self, model, loader, criterion, optimizer, config):\n","        super().__init__(model, loader, criterion, optimizer, config)\n","\n","    def run_one_epoch_train(self, epoch):\n","        train_loss = 0\n","\n","        self.model.train()\n","\n","        for idx, (input, pos, neg) in enumerate(self.train_loader):\n","            if self.use_cuda:\n","                input = input.cuda()\n","                pos = pos.cuda()\n","                neg = neg.cuda()\n","\n","            output, pos_output, neg_output = self.model(input, pos, neg)\n","            loss = self.criterion(output, pos_output, neg_output)\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            if (idx + 1) % 100 == 0:\n","                print(\"[Epoch {}/{}] iter {}/{} loss: {:.5f}\".format(epoch + 1, self.epochs, idx + 1, len(self.train_loader), loss.item()), flush=True)\n","\n","        train_loss /= len(self.train_loader)\n","\n","        return train_loss\n","\n","    def run_one_epoch_eval(self, epoch):\n","        valid_loss = 0\n","\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            for idx, (input, pos, neg) in enumerate(self.valid_loader):\n","                if self.use_cuda:\n","                    input = input.cuda()\n","                    pos = pos.cuda()\n","                    neg = neg.cuda()\n","                output, pos_output, neg_output = self.model(input, pos, neg)\n","                loss = self.criterion(output, pos_output, neg_output)\n","                valid_loss += loss.item()\n","\n","        valid_loss /= len(self.valid_loader)\n","\n","        return valid_loss"],"metadata":{"id":"lq9BBGUZn4bS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = \"WikiText2\" # or \"WikiText103\"\n","exp_dir = \"./exp\"\n","\n","config = {\n","    \"system\": {\n","        \"seed\": 111,\n","        \"use_cuda\":  torch.cuda.is_available(),\n","        \"eps\": 1e-12\n","    },\n","    \"dataset\": dataset,\n","    \"vocab\": {\n","        \"min_freq\": 50\n","    },\n","    \"vocab_path\": os.path.join(exp_dir, dataset, \"vocab/vocab.pth\"),\n","    \"nagative_sampling\": {\n","        \"sampling\": \"table\", # \"frequency\"\n","        \"num_samples\": 20,\n","        \"smooth\": 0.75\n","    },\n","    \"context_size\": 4,\n","    \"model\": {\n","        \"embed_dim\": 300\n","    },\n","    \"optim\": {\n","        \"lr\": 1e-3\n","    },\n","    \"batch_size\": 96,\n","    \"epochs\": 100,\n","    \"model_dir\": os.path.join(exp_dir, dataset, \"CBoW_negative-sampling/model\"),\n","    \"loss_dir\": os.path.join(exp_dir, dataset, \"CBoW_negative-sampling/loss\"),\n","    \"continue_from\": None # None or os.path.join(exp_dir, dataset, \"CBoW_negative-sampling/model/last.pth\")\n","}"],"metadata":{"id":"mu8fimrF05d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(config[\"system\"][\"seed\"])\n","torch.manual_seed(config[\"system\"][\"seed\"])"],"metadata":{"id":"OxDZ6LHun51v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config[\"dataset\"] == \"WikiText2\":\n","    train_iter = torchtext.datasets.WikiText2(root=\"./\", split='train')\n","    valid_iter = torchtext.datasets.WikiText2(root=\"./\", split='valid')\n","elif config[\"dataset\"] == \"WikiText103\":\n","    train_iter = torchtext.datasets.WikiText103(root=\"./\", split='train')\n","    valid_iter = torchtext.datasets.WikiText103(root=\"./\", split='valid')\n","else:\n","    raise NotImplementedError(\"Not support {}.\".format(config[\"dataset\"]))\n","\n","train_iter = to_map_style_dataset(train_iter)\n","valid_iter = to_map_style_dataset(valid_iter)"],"metadata":{"id":"He6tg2BzSiMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n","\n","if os.path.exists(config[\"vocab_path\"]):\n","    vocab = torch.load(config[\"vocab_path\"])\n","else:\n","    vocab = build_vocab(train_iter, tokenizer, min_freq=config[\"vocab\"][\"min_freq\"])\n","    vocab_dir = os.path.dirname(config[\"vocab_path\"])\n","    os.makedirs(vocab_dir, exist_ok=True)\n","    torch.save(vocab, config[\"vocab_path\"])\n","\n","text_pipeline = lambda x: vocab(tokenizer(x))\n","\n","neg_freq = build_neg_freq(train_iter, vocab, tokenizer, smooth=config[\"nagative_sampling\"][\"smooth\"])"],"metadata":{"id":"eTZmPx-jSwHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader = {}\n","if config[\"nagative_sampling\"][\"sampling\"] == \"table\":\n","    neg_table = build_neg_table(neg_freq)\n","    loader[\"train\"] = torch.utils.data.DataLoader(train_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn_table, text_pipeline=text_pipeline, neg_table=neg_table, context_size=config[\"context_size\"], num_neg_samples=config[\"nagative_sampling\"][\"num_samples\"]))\n","    loader[\"valid\"] = torch.utils.data.DataLoader(valid_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn_table, text_pipeline=text_pipeline, neg_table=neg_table, context_size=config[\"context_size\"], num_neg_samples=config[\"nagative_sampling\"][\"num_samples\"]))\n","else:\n","    warnings.warn(\"Frequency-based sampling may take long time.\", UserWarning)\n","    loader[\"train\"] = torch.utils.data.DataLoader(train_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn_freq, text_pipeline=text_pipeline, neg_freq=neg_freq, context_size=config[\"context_size\"], num_neg_samples=config[\"nagative_sampling\"][\"num_samples\"]))\n","    loader[\"valid\"] = torch.utils.data.DataLoader(valid_iter, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=partial(collate_fn_freq, text_pipeline=text_pipeline, neg_freq=neg_freq, context_size=config[\"context_size\"], num_neg_samples=config[\"nagative_sampling\"][\"num_samples\"]))"],"metadata":{"id":"7ti3agshn7CD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = CBoWNegativeSampling(vocab_size=len(vocab), embed_dim=config[\"model\"][\"embed_dim\"])\n","print(model)"],"metadata":{"id":"C1YC1aP0n9k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if config[\"system\"][\"use_cuda\"]:\n","    model.cuda()\n","    print(\"Uses CUDA.\")\n","else:\n","    print(\"Does NOT use CUDA.\")"],"metadata":{"id":"DD3MhQc_MQ_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=config[\"optim\"][\"lr\"])"],"metadata":{"id":"asjhWBw8n_oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = NegativeSamplingLoss()"],"metadata":{"id":"Y3_GkzgtoBFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"bfdDiUDO9b8B"}},{"cell_type":"code","source":["trainer = AdhocTrainer(model, loader, criterion, optimizer, config)\n","trainer.run()"],"metadata":{"id":"XuS7gOkVoCMf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Examine"],"metadata":{"id":"0Td3NaOu9dnl"}},{"cell_type":"code","source":["from word2vec import Word2Vec"],"metadata":{"id":"vaqRPPrIJ39K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = os.path.join(config[\"model_dir\"], \"last.pth\")\n","package = torch.load(model_path, map_location=lambda storage, loc: storage)\n","\n","model = CBoWNegativeSampling(vocab_size=len(vocab), embed_dim=config[\"model\"][\"embed_dim\"])\n","model.load_state_dict(package[\"state_dict\"])"],"metadata":{"id":"OtpN4zrbEH6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2vec = Word2Vec(model.get_embedding_weights(), vocab, eps=config[\"system\"][\"eps\"])"],"metadata":{"id":"ExWt_FgqG2hm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similar_words = word2vec.get_similar_words(\"mother\")\n","print(similar_words)"],"metadata":{"id":"2keMwNkJG3KW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["son_vec, man_vec, woman_vec = word2vec([\"son\", \"man\", \"woman\"])\n","similar_words = word2vec.get_similar_words_from_vec(son_vec - man_vec + woman_vec)\n","print(similar_words)"],"metadata":{"id":"AWlkUsiyGC-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"kLomc72fPW-V"},"execution_count":null,"outputs":[]}]}