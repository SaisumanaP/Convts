{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"music-source-separation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNeMo95TALmIdgqvlg+YjaF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e5VTKssvFchI"},"source":["# Music Source Separation by Pretrained Models\n","If you want to separate your own music files, see\n","- `egs/tutorials/conv-tasnet/separate_music.ipynb` for Conv-TasNet\n","- `egs/tutorials/mm-dense-lstm/separate_music.ipynb` for MMDenseLSTM\n","- `egs/tutorials/umx/separate_music.ipynb` for Open-Unmix\n","- `egs/tutorials/xumx/separate_music.ipynb` for CrossNet-Open-Unmix\n","- `egs/tutorials/d3net/separate_music.ipynb` for D3Net"]},{"cell_type":"code","metadata":{"id":"eiAAeD-sFW9m"},"source":["%%bash\n","git clone https://github.com/tky823/DNN-based_source_separation.git\n","\n","cd \"./DNN-based_source_separation/egs/tutorials/\"\n","\n","# To install torch & torchaudio\n","pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hRxppAZFvKf"},"source":["%%bash\n","# Download music datset\n","wget \"https://zenodo.org/api/files/1ff52183-071a-4a59-923f-7a31c4762d43/MUSDB18-7-STEMS.zip\"\n","unzip \"./MUSDB18-7-STEMS.zip\"\n","\n","# Convert .mp4 to .wav\n","cd \"./train\"\n","\n","for stem in *.stem.mp4 ; do\n","    name=`echo $stem | awk -F\".stem.mp4\" '{$0=$1}1'`;\n","    echo \"$stem\"\n","    mkdir \"$name\"\n","    cd \"$name\"\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:0 -vn mixture.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:1 -vn drums.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:2 -vn bass.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:3 -vn other.wav\n","    ffmpeg -loglevel panic -i \"../${stem}\" -map 0:4 -vn vocals.wav\n","    cd \"../\"\n","done"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sm21an1_GwgT"},"source":["import sys\n","sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MoIuAY2GwdY"},"source":["import IPython.display as ipd\n","import torch\n","import torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2xEU6rUGway"},"source":["from models.conv_tasnet import ConvTasNet\n","from models.mm_dense_lstm import MMDenseLSTM, ParallelMMDenseLSTM\n","from models.umx import OpenUnmix, ParallelOpenUnmix\n","from models.xumx import CrossNetOpenUnmix\n","from models.d3net import D3Net, ParallelD3Net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HX2S7-B1IE1M"},"source":["name = \"ANiMAL - Rockshow\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RqRAt917G0iZ"},"source":["waveform_bass, sample_rate = torchaudio.load(\"/content/train/{}/bass.wav\".format(name))\n","waveform_drums, sample_rate = torchaudio.load(\"/content/train/{}/drums.wav\".format(name))\n","waveform_other, sample_rate = torchaudio.load(\"/content/train/{}/other.wav\".format(name))\n","waveform_vocals, sample_rate = torchaudio.load(\"/content/train/{}/vocals.wav\".format(name))\n","\n","print(\"bass\")\n","display(ipd.Audio(waveform_bass, rate=sample_rate))\n","print(\"drums\")\n","display(ipd.Audio(waveform_drums, rate=sample_rate))\n","print(\"other\")\n","display(ipd.Audio(waveform_other, rate=sample_rate))\n","print(\"vocals\")\n","display(ipd.Audio(waveform_vocals, rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSTTjIzoHzLx"},"source":["mixture = waveform_bass + waveform_drums + waveform_other + waveform_vocals\n","display(ipd.Audio(mixture, rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS1DAoOgHWRA"},"source":["model = ConvTasNet.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    mean = input.mean(dim=3, keepdim=True)\n","    std = input.std(dim=3, keepdim=True)\n","    input = (input - mean) / std\n","    output = model(input)\n","    output = std * output + mean\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRv5wMoFVoWO"},"source":["model = ParallelMMDenseLSTM.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelMMDenseLSTM.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOsPoUeMW2ga"},"source":["model = ParallelOpenUnmix.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelOpenUnmix.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zidt4JLZbpGx"},"source":["model = CrossNetOpenUnmix.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = CrossNetOpenUnmix.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l34GHed1Xa4N"},"source":["model = ParallelD3Net.build_from_pretrained(task=\"musdb18\", sample_rate=sample_rate)\n","wrapper_model = ParallelD3Net.TimeDomainWrapper(model, n_fft=model.n_fft, hop_length=model.hop_length, window_fn=model.window_fn)\n","wrapper_model.eval()\n","\n","input = mixture.unsqueeze(dim=0).unsqueeze(dim=1)\n","with torch.no_grad():\n","    output = wrapper_model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.unbind(output, dim=0)\n","\n","for idx, target in enumerate(wrapper_model.sources):\n","    print(target)\n","    display(ipd.Audio(estimated[idx], rate=sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gspua4H6ZCBn"},"source":[""],"execution_count":null,"outputs":[]}]}